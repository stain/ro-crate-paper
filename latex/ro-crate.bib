
@article{doi:10.1093/nar/gkq429,
title = {{myExperiment}: a repository and social network for the sharing of bioinformatics workflows.},
author = {Goble, Carole A and Bhagat, Jiten and Aleksejevs, Sergejs and Cruickshank, Don and Michaelides, Danius and Newman, David and Borkum, Mark and Bechhofer, Sean and Roos, Marco and Li, Peter and De Roure, David},
pages = {W677-82},
year = {2010},
month = {jul},
day = {1},
urldate = {2021-05-04},
journal = {Nucleic Acids Research},
volume = {38},
number = {Web Server issue},
doi = {10.1093/nar/gkq429},
pmid = {20501605},
pmcid = {PMC2896080},
sciwheel-projects = {ro-crate-paper},
abstract = {{myExperiment} (http://www.myexperiment.org) is an online research environment that supports the social sharing of bioinformatics workflows. These workflows are procedures consisting of a series of computational tasks using web services, which may be performed on data from its retrieval, integration and analysis, to the visualization of the results. As a public repository of workflows, {myExperiment} allows anybody to discover those that are relevant to their research, which can then be reused and repurposed to their specific requirements. Conversely, developers can submit their workflows to {myExperiment} and enable them to be shared in a secure manner. Since its release in 2007, {myExperiment} currently has over 3500 registered users and contains more than 1000 workflows. The social aspect to the sharing of these workflows is facilitated by registered users forming virtual communities bound together by a common interest or research project. Contributors of workflows can build their reputation within these communities by receiving feedback and credit from individuals who reuse their work. Further documentation about {myExperiment} including its {REST} web service is available from http://wiki.myexperiment.org. Feedback and requests for support can be sent to bugs@myexperiment.org.}
}
@article{doi:10.1038/sdata.2016.18,
title = {The {FAIR} Guiding Principles for scientific data management and stewardship.},
author = {Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, I Jsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E and Bouwman, Jildau and Brookes, Anthony J and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J G and Groth, Paul and Goble, Carole and Grethe, Jeffrey S and Heringa, Jaap and 't Hoen, Peter A C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J and Martone, Maryann E and Mons, Albert and Packer, Abel L and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
pages = {160018},
year = {2016},
month = {mar},
day = {15},
urldate = {2018-07-13},
journal = {Scientific data},
volume = {3},
issn = {2052-4463},
doi = {10.1038/sdata.2016.18},
pmid = {26978244},
pmcid = {PMC4792175},
sciwheel-projects = {ro-crate-paper},
abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders-representing academia, industry, funding agencies, and scholarly publishers-have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the {FAIR} Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the {FAIR} Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the {FAIR} Principles, and includes the rationale behind them, and some exemplar implementations in the community.}
}
@article{doi:10.1186/1471-2105-11-S12-S5,
title = {Community-driven computational biology with Debian Linux.},
author = {Möller, Steffen and Krabbenhöft, Hajo Nils and Tille, Andreas and Paleino, David and Williams, Alan and Wolstencroft, Katy and Goble, Carole and Holland, Richard and Belhachemi, Dominique and Plessy, Charles},
pages = {S5},
year = {2010},
month = {dec},
day = {21},
urldate = {2021-05-04},
journal = {{BMC} Bioinformatics},
volume = {11 Suppl 12},
doi = {10.1186/1471-2105-11-S12-S5},
pmid = {21210984},
pmcid = {PMC3040531},
sciwheel-projects = {ro-crate-paper},
abstract = {{BACKGROUND}: The Open Source movement and its technologies are popular in the bioinformatics community because they provide freely available tools and resources for research. In order to feed the steady demand for updates on software and associated data, a service infrastructure is required for sharing and providing these tools to heterogeneous computing environments. {RESULTS}: The Debian Med initiative provides ready and coherent software packages for medical informatics and bioinformatics. These packages can be used together in Taverna workflows via the {UseCase} plugin to manage execution on local or remote machines. If such packages are available in cloud computing environments, the underlying hardware and the analysis pipelines can be shared along with the software. {CONCLUSIONS}: Debian Med closes the gap between developers and users. It provides a simple method for offering new releases of software and data resources, thus provisioning a local infrastructure for computational biology. For geographically distributed teams it can ensure they are working on the same versions of tools, in the same conditions. This contributes to the world-wide networking of researchers.}
}
@article{doi:10.1016/j.future.2011.08.004,
title = {Why linked data is not enough for scientists},
author = {Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier, Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and Gamble, Matthew and Michaelides, Danius and Owen, Stuart and Newman, David and Sufi, Shoaib and Goble, Carole},
pages = {599-611},
year = {2013},
month = {feb},
urldate = {2021-05-04},
journal = {Future Generation Computer Systems},
volume = {29},
number = {2},
issn = {0167739X},
doi = {10.1016/j.future.2011.08.004},
sciwheel-projects = {ro-crate-paper},
abstract = {Scientific data represents a significant portion of the linked open data cloud and scientists stand to benefit from the data fusion capability this will afford. Publishing linked data into the cloud, however, does not ensure the required reusability. Publishing has requirements of provenance, quality, credit, attribution and methods to provide the reproducibility that enables validation of results. In this paper we make the case for a scientific data publication model on top of linked data and introduce the notion of Research Objects as first class citizens for sharing and publishing.}
}
@article{doi:10.1016/j.future.2017.01.012,
title = {Scientific workflows for computational reproducibility in the life sciences: Status, challenges and opportunities},
author = {Cohen-Boulakia, Sarah and Belhajjame, Khalid and Collin, Olivier and Chopard, Jérôme and Froidevaux, Christine and Gaignard, Alban and Hinsen, Konrad and Larmande, Pierre and Bras, Yvan Le and Lemoine, Frédéric and Mareuil, Fabien and Ménager, Hervé and Pradal, Christophe and Blanchet, Christophe},
pages = {284-298},
year = {2017},
month = {oct},
urldate = {2018-07-13},
journal = {Future Generation Computer Systems},
volume = {75},
issn = {0167739X},
doi = {10.1016/j.future.2017.01.012},
sciwheel-projects = {ro-crate-paper},
abstract = {With the development of new experimental technologies, biologists are faced with an avalanche of data to be computationally analyzed for scientific advancements and discoveries to emerge. Faced with the complexity of analysis pipelines, the large number of computational tools, and the enormous amount of data to manage, there is compelling evidence that many if not most scientific discoveries will not stand the test of time: increasing the reproducibility of computed results is of paramount importance. The objective we set out in this paper is to place scientific workflows in the context of reproducibility. To do so, we define several kinds of repro-ducibility that can be reached when scientific workflows are used to perform experiments. We characterize and define the criteria that need to be catered for by reproducibility-friendly scientific workflow systems, and use such criteria to place several representative and widely used workflow systems and companion tools within such a framework. We also discuss the remaining challenges posed by reproducible scientific workflows in the life sciences. Our study was guided by three use cases from the life science domain involving in silico experiments.}
}
@article{doi:10.1007/s41019-017-0050-4,
title = {Robust Cross-Platform Workflows: How Technical and Scientific Communities Collaborate to Develop, Test and Share Best Practices for Data Analysis},
author = {Möller, Steffen and Prescott, Stuart W. and Wirzenius, Lars and Reinholdtsen, Petter and Chapman, Brad and Prins, Pjotr and Soiland-Reyes, Stian and Klötzl, Fabian and Bagnacani, Andrea and Kalaš, Matúš and Tille, Andreas and Crusoe, Michael R.},
pages = {232-244},
year = {2017},
month = {nov},
day = {16},
urldate = {2018-07-13},
journal = {Data Science and Engineering},
volume = {2},
number = {3},
issn = {2364-1185},
doi = {10.1007/s41019-017-0050-4},
sciwheel-projects = {ro-crate-paper},
abstract = {Information integration and workflow technologies for data analysis have always been major fields of investigation in bioinformatics. A range of popular workflow suites are available to support analyses in computational biology. Commercial providers tend to offer prepared applications remote to their clients. However, for most academic environments with local expertise, novel data collection techniques or novel data analysis, it is essential to have all the flexibility of open-source tools and open-source workflow descriptions. Workflows in data-driven science such as computational biology have considerably gained in complexity. New tools or new releases with additional features arrive at an enormous pace, and new reference data or concepts for quality control are emerging. A well-abstracted workflow and the exchange of the same across work groups have an enormous impact on the efficiency of research and the further development of the field. High-throughput sequencing adds to the avalanche of data available in the field; efficient computation and, in particular, parallel execution motivate the transition from traditional scripts and Makefiles to workflows. We here review the extant software development and distribution model with a focus on the role of integration testing and discuss the effect of common workflow language on distributions of open-source scientific software to swiftly and reliably provide the tools demanded for the execution of such formally described workflows. It is contended that, alleviated from technical differences for the execution on local machines, clusters or the cloud, communities also gain the technical means to test workflow-driven interaction across several software packages.}
}
@article{doi:10.3389/fninf.2017.00069,
title = {Re-run, Repeat, Reproduce, Reuse, Replicate: Transforming Code into Scientific Contributions.},
author = {Benureau, Fabien C Y and Rougier, Nicolas P},
pages = {69},
year = {2017},
urldate = {2021-05-04},
journal = {Frontiers in Neuroinformatics},
volume = {11},
doi = {10.3389/fninf.2017.00069},
pmid = {29354046},
pmcid = {PMC5758530},
sciwheel-projects = {ro-crate-paper},
abstract = {Scientific code is different from production software. Scientific code, by producing results that are then analyzed and interpreted, participates in the elaboration of scientific conclusions. This imposes specific constraints on the code that are often overlooked in practice. We articulate, with a small example, five characteristics that a scientific code in computational science should possess: re-runnable, repeatable, reproducible, reusable, and replicable. The code should be executable (re-runnable) and produce the same result more than once (repeatable); it should allow an investigator to reobtain the published results (reproducible) while being easy to use, understand and modify (reusable), and it should act as an available reference for any ambiguity in the algorithmic descriptions of the article (replicable).}
}
@article{doi:10.1038/s41592-018-0046-7,
title = {Bioconda: sustainable and comprehensive software distribution for the life sciences.},
author = {Grüning, Björn and Dale, Ryan and Sjödin, Andreas and Chapman, Brad A and Rowe, Jillian and Tomkins-Tinch, Christopher H and Valieris, Renan and Köster, Johannes and Bioconda Team},
pages = {475-476},
year = {2018},
urldate = {2018-07-13},
journal = {Nature Methods},
volume = {15},
number = {7},
issn = {1548-7091},
doi = {10.1038/s41592-018-0046-7},
pmid = {29967506},
sciwheel-projects = {ro-crate-paper}
}
@article{doi:10.1016/j.cels.2018.03.014,
title = {Practical computational reproducibility in the life sciences.},
author = {Grüning, Björn and Chilton, John and Köster, Johannes and Dale, Ryan and Soranzo, Nicola and van den Beek, Marius and Goecks, Jeremy and Backofen, Rolf and Nekrutenko, Anton and Taylor, James},
pages = {631-635},
year = {2018},
month = {jun},
day = {27},
urldate = {2018-07-13},
journal = {Cell Systems},
volume = {6},
number = {6},
issn = {24054712},
doi = {10.1016/j.cels.2018.03.014},
pmid = {29953862},
pmcid = {PMC6263957},
sciwheel-projects = {ro-crate-paper},
abstract = {Many areas of research suffer from poor reproducibility, particularly in computationally intensive domains where results rely on a series of complex methodological decisions that are not well captured by traditional publication approaches. Various guidelines have emerged for achieving reproducibility, but implementation of these practices remains difficult due to the challenge of assembling software tools plus associated libraries, connecting tools together into pipelines, and specifying parameters. Here, we discuss a suite of cutting-edge technologies that make computational reproducibility not just possible, but practical in both time and effort. This suite combines three well-tested components-a system for building highly portable packages of bioinformatics software, containerization and virtualization technologies for isolating reusable execution environments for these packages, and workflow systems that automatically orchestrate the composition of these packages for entire pipelines-to achieve an unprecedented level of computational reproducibility. We also provide a practical implementation and five recommendations to help set a typical researcher on the path to performing data analyses reproducibly. Copyright \copyright 2018 Elsevier Inc. All rights reserved.}
}
@techreport{doi:10.17487/rfc3987,
title = {Internationalized resource identifiers ({IRI}s)},
author = {Duerst, M. and Suignard, M.},
publisher = {{RFC} Editor},
url = {https://www.rfc-editor.org/info/rfc3987},
year = {2005},
month = {jan},
urldate = {2018-07-15},
doi = {10.17487/rfc3987},
sciwheel-projects = {ro-crate-paper}
}
@article{doi:10.1038/s41586-019-0965-1,
title = {A new genomic blueprint of the human gut microbiota.},
author = {Almeida, Alexandre and Mitchell, Alex L and Boland, Miguel and Forster, Samuel C and Gloor, Gregory B and Tarkowska, Aleksandra and Lawley, Trevor D and Finn, Robert D},
pages = {499-504},
year = {2019},
month = {feb},
day = {11},
urldate = {2021-05-04},
journal = {Nature},
volume = {568},
number = {7753},
issn = {0028-0836},
doi = {10.1038/s41586-019-0965-1},
pmid = {30745586},
pmcid = {PMC6784870},
sciwheel-projects = {ro-crate-paper},
abstract = {The composition of the human gut microbiota is linked to health and disease, but knowledge of individual microbial species is needed to decipher their biological roles. Despite extensive culturing and sequencing efforts, the complete bacterial repertoire of the human gut microbiota remains undefined. Here we identify 1,952 uncultured candidate bacterial species by reconstructing 92,143 metagenome-assembled genomes from 11,850 human gut microbiomes. These uncultured genomes substantially expand the known species repertoire of the collective human gut microbiota, with a 281\% increase in phylogenetic diversity. Although the newly identified species are less prevalent in well-studied populations compared to reference isolate genomes, they improve classification of understudied African and South American samples by more than 200\%. These candidate species encode hundreds of newly identified biosynthetic gene clusters and possess a distinctive functional capacity that might explain their elusive nature. Our work expands the known diversity of uncultured gut bacteria, which provides unprecedented resolution for taxonomic and functional characterization of the intestinal microbiota.}
}
@article{doi:10.1371/journal.pbio.3000099,
title = {Enabling precision medicine via standard communication of {HTS} provenance, analysis, and results.},
author = {Alterovitz, Gil and Dean, Dennis and Goble, Carole and Crusoe, Michael R and Soiland-Reyes, Stian and Bell, Amanda and Hayes, Anais and Suresh, Anita and Purkayastha, Anjan and King, Charles H and Taylor, Dan and Johanson, Elaine and Thompson, Elaine E and Donaldson, Eric and Morizono, Hiroki and Tsang, Hsinyi and Vora, Jeet K and Goecks, Jeremy and Yao, Jianchao and Almeida, Jonas S and Keeney, Jonathon and Addepalli, {KanakaDurga} and Krampis, Konstantinos and Smith, Krista M and Guo, Lydia and Walderhaug, Mark and Schito, Marco and Ezewudo, Matthew and Guimera, Nuria and Walsh, Paul and Kahsay, Robel and Gottipati, Srikanth and Rodwell, Timothy C and Bloom, Toby and Lai, Yuching and Simonyan, Vahan and Mazumder, Raja},
pages = {e3000099},
year = {2018},
month = {dec},
day = {31},
urldate = {2021-05-04},
journal = {{PLoS} Biology},
volume = {16},
number = {12},
doi = {10.1371/journal.pbio.3000099},
pmid = {30596645},
pmcid = {PMC6338479},
sciwheel-projects = {ro-crate-paper},
abstract = {A personalized approach based on a patient's or pathogen's unique genomic sequence is the foundation of precision medicine. Genomic findings must be robust and reproducible, and experimental data capture should adhere to findable, accessible, interoperable, and reusable ({FAIR}) guiding principles. Moreover, effective precision medicine requires standardized reporting that extends beyond wet-lab procedures to computational methods. The {BioCompute} framework (https://w3id.org/biocompute/1.3.0) enables standardized reporting of genomic sequence data provenance, including provenance domain, usability domain, execution domain, verification kit, and error domain. This framework facilitates communication and promotes interoperability. Bioinformatics computation instances that employ the {BioCompute} framework are easily relayed, repeated if needed, and compared by scientists, regulators, test developers, and clinicians. Easing the burden of performing the aforementioned tasks greatly extends the range of practical application. Large clinical trials, precision medicine, and regulatory submissions require a set of agreed upon standards that ensures efficient communication and documentation of genomic analyses. The {BioCompute} paradigm and the resulting {BioCompute} Objects ({BCOs}) offer that standard and are freely accessible as a {GitHub} organization (https://github.com/biocompute-objects) following the "Open-Stand.org principles for collaborative open standards development." With high-throughput sequencing ({HTS}) studies communicated using a {BCO}, regulatory agencies (e.g., Food and Drug Administration [{FDA}]), diagnostic test developers, researchers, and clinicians can expand collaboration to drive innovation in precision medicine, potentially decreasing the time and cost associated with next-generation sequencing workflow exchange, reporting, and regulatory reviews.}
}
@article{doi:10.6084/m9.figshare.3115156.v2,
title = {Common Workflow Language, v1.0},
author = {Amstutz, Peter and Crusoe, Michael R. and Tijanić, Nebojša and Chapman, Brad and Chilton, John and Heuer, Michael and Kartashov, Andrey and Leehr, Dan and Ménager, Hervé and Nedeljkovich, Maya and Scales, Matt and Soiland-Reyes, Stian and Stojanovic, Luka},
url = {https://www.commonwl.org/v1.0/},
year = {2016},
urldate = {2021-05-04},
journal = {Figshare},
doi = {10.6084/m9.figshare.3115156.v2},
sciwheel-projects = {ro-crate-paper},
abstract = {The Common Workflow Language ({CWL}) is an informal, multi-vendor working group consisting of various organizations and individuals that have an interest in portability of data analysis workflows. Our goal is to create specifications that enable data scientists to describe analysis tools and workflows that are powerful, easy to use, portable, and support reproducibility.{CWL} builds on technologies such as {JSON}-{LD} and Avro for data modeling and Docker for portable runtime environments. {CWL} is designed to express workflows for data-intensive science, such as Bioinformatics, Medical Imaging, Chemistry, Physics, and Astronomy.This is v1.0 of the {CWL} tool and workflow specification, released on 2016-07-08.The specification, in {HTML} format, is in the draft-3/docs folder.}
}
@article{doi:10.3233/DS-190026,
title = {Towards {FAIR} principles for research software},
author = {Lamprecht, Anna-Lena and Garcia, Leyla and Kuzak, Mateusz and Martinez, Carlos and Arcila, Ricardo and Martin Del Pico, Eva and Dominguez Del Angel, Victoria and van de Sandt, Stephanie and Ison, Jon and Martinez, Paula Andrea and {McQuilton}, Peter and Valencia, Alfonso and Harrow, Jennifer and Psomopoulos, Fotis and Gelpi, Josep Ll. and Chue Hong, Neil and Goble, Carole and Capella-Gutierrez, Salvador},
pages = {1-23},
year = {2019},
month = {nov},
day = {13},
urldate = {2021-02-22},
journal = {Déviance et société},
issn = {24518492},
doi = {10.3233/{DS}-190026},
sciwheel-projects = {ro-crate-paper}
}
@article{doi:10.1162/dint_a_00033,
title = {{FAIR} Computational Workflows},
author = {Goble, Carole and Cohen-Boulakia, Sarah and Soiland-Reyes, Stian and Garijo, Daniel and Gil, Yolanda and Crusoe, Michael R. and Peters, Kristian and Schober, Daniel},
pages = {108-121},
year = {2019},
month = {nov},
day = {1},
urldate = {2021-05-04},
journal = {Data Intelligence},
issn = {2641-{435X}},
doi = {10.1162/dint\_a\_00033},
sciwheel-projects = {ro-crate-paper},
abstract = {Computational workflows describe the complex multi-step methods that are used for data collection, data preparation, analytics, predictive modelling, and simulation that lead to new data products. They can inherently contribute to the {FAIR} data principles: by processing data according to established metadata; by creating metadata themselves during the processing of data; and by tracking and recording data provenance. These properties aid data quality assessment and contribute to secondary data usage. Moreover, workflows are digital objects in their own right. This paper argues that {FAIR} principles for workflows need to address their specific nature in terms of their composition of executable software steps, their provenance, and their development.}
}
@article{doi:10.5281/zenodo.4605654,
title = {Implementing {FAIR} Digital Objects in the {EOSC}-Life Workflow Collaboratory},
author = {Goble, Carole and Soiland-Reyes, Stian and Bacall, Finn and Owen, Stuart and Williams, Alan and Eguinoa, Ignacio and Droesbeke, Bert and Leo, Simone and Pireddu, Luca and Rodriguez-Navas, Laura and Fernández, José Mª and Capella-Gutierrez, Salvador and Ménager, Hervé and Grüning, Björn and Serrano-Solano, Beatriz and Ewels, Philip and Coppens, Frederik},
year = {2021},
urldate = {2021-03-29},
journal = {Zenodo},
doi = {10.5281/zenodo.4605654},
sciwheel-projects = {ro-crate-paper},
abstract = {The practice of performing computational processes using workflows has taken hold in the biosciences as the discipline becomes increasingly computational. The {COVID}-19 pandemic has spotlighted the importance of systematic and shared analysis of {SARS}-{CoV}-2 and its data processing pipelines. This is coupled with a drive in the community towards adopting {FAIR} practices (Findable, Accessible, Interoperable, and Reusable) not just for data, but also for workflows, and to improve the reproducibility of processes, both manual and computational. {EOSC}-Life brings together 13 of the Life Science {\textquoteleftESFRI\textquoteright} research infrastructures to create an open, digital and collaborative space for biological and medical research. The project is developing a cloud-based workflow collaboratory to drive implementation of {FAIR} workflows across disciplines and {RI} boundaries, and foster tool- focused collaborations and reuse between communities via the sharing of data analysis workflows. The collaboratory aims to provide a framework for researchers and workflow specialists to use and reuse workflows. As such it is an example of the Canonical Workflow Frameworks for Research ({CWFR}) vision in practice. {EOSC}-Life is made up of established research infrastructures ranging from biobanking and clinical trial management, through to coordinating biomedical imaging and plant phenotyping to multi-omic and systems-based data analysis. The heterogeneity of the disciplines is reflected in the diversity of their data analysis needs and practices and the variety of workflow management systems they use. Many have specialist platforms developed over years. Workflow management systems in common use include Galaxy, Snakemake, and Nextflow, and more specialist, domain-specific systems such as {SCIPION}. To serve the needs of this established and diverse community, {EOSC}-Life has developed {WorkflowHub} as an inclusive workflow registry, agnostic to any Workflow Management System ({WfMS}). {WorkflowHub} aims to incorporate their workflows in partnership with the {WfMS}, to embed the registration of workflows in the community processes, e.g. based on pre-existing workflow repositories. The registry adopts common practices, e.g.use of {GitHub} repositories, and supports integration with the ecosystem of tool packages, assisted by registries (bio.tools, biocontainers), and services for testing and benchmarking workflows ({OpenEBench}, {LifeMonitor}). As an umbrella registry, the Hub makes workflows Findable and Accessible by indexing workflows across workflow management systems and their native repositories, while providing rich standardized metadata. Interoperability and Reusability is supported by standardized descriptions of workflows and packaging of workflow components, developed in close collaboration with the communities. The {WorkflowHub} creates a place for registering and discovering libraries of workflows developed by collaborating teams, with suitable features for versioning, credit, analytics, and import/export needed to support the reuse of workflows, the development of sub-workflows as canonical steps and ultimately the identification of common patterns in the workflows. At the heart of the collaboratory is a Digital Object framework for documenting and exchanging workflows annotated with machine processable metadata produced and consumed by the participating platforms. The Digital Object framework is founded on several needs: Describing a workflow and its steps in a canonical, normalised and {WfMS} independent way: we use the Common Workflow Language ({CWL}), more specifically the Abstract {CWL} (non-executable) description variant to accompany the native workflow definitions. This presents the structure, composed tools and external interface in an interoperable way across workflow languages. {WfMS} can generate abstract {CWL}, already demonstrated for Galaxy, next to the \textquoteleftnative\textquoteright Galaxy workflow description. This language duality is an important retention aspect of reproducibility, as the structure and metadata of the workflow can be accessed independent of its native format as {CWL}, even if that may no longer be executable, capturing the canonical workflow in a {FAIR} format. The co-presence of the native format enables direct reuse in the specific {WfMS}, benefitting from all its features. Metadata about a workflow and its tools using a minimal information model: we use the Bioschemas profiles Computational Tool, Computational Workflow and Formal Parameter which are discipline independent, opinionated conventions for using schema.org annotations. Bioschemas enables us to capture and publish workflow registrations and their metadata as {FAIR} Digital Objects. The {EDAM} Ontology is further used to add bioinformatics-specific metadata, such as strong typing of inputs and outputs, within both Abstract {CWL} and Bioschemas annotations. Organising and packaging the definitions and components of a workflow with their associated objects such as test data: we use a Workflow profile specialisation of {RO}-Crate, a community developed standardised approach for research output packaging with rich metadata. {RO}-Crate provides us the ability to package executable workflows, their components such as example and test data, abstract {CWL}, diagrams and their documentation. This makes workflows more readily re-usable. {RO}-Crate is the base unit of upload and download at the {WorkflowHub}. As {CWFR} Digital Objects of workflows, {RO}-Crates are activation-ready and circulated between the different services for execution and testing. Identifiers for all the components: like {FAIR} Digital Objects, {RO}-Crates can be metadata-rich bags of identifiers and can themselves be assigned permanent identifiers. This enables the full description of a computational analysis, from input data, over tools and workflows, to final results. Using these components we have built an environment that supports the Workflow Life Cycle, from abstract description, through to a specific rendering in a {WfMS} to its execution and the documentation of its run provenance, results and continued testing.}
}
@misc{neylon_blog_post_2017,
title = {As a {researcher\textellipsisI\textquoterightm} a bit bloody fed up with Data Management},
author = {Neylon, Cameron},
journal = {Science In The Open},
url = {https://cameronneylon.net/blog/as-a-researcher-im-a-bit-bloody-fed-up-with-data-management/},
year = {2017},
month = {jul},
day = {16},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {BLOG\_POST}
}

@misc{chipseq/nf-core,
title = {chipseq/nf-core outputs},
url = {https://nf-co.re/chipseq/1.2.2/output},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@article{doi:10.5281/zenodo.4711243,
title = {nf-core/chipseq: nf-core/chipseq v1.2.2 - Rusty Mole},
author = {Patel, Harshil and Wang, Chuan and Ewels, Phil and Silva, Tiago Chedraoui and Peltzer, Alexander and Behrens, Drew and Garcia, Maxime and Mashehu and Rotholandus and Haglund, Sofia and Kretzschmar, Winni},
year = {2021},
urldate = {2021-05-04},
journal = {Zenodo},
doi = {10.5281/zenodo.4711243},
sciwheel-projects = {ro-crate-paper},
abstract = {[1.2.2] - 2021-04-22 \#206 - Minor patch release to fix Conda environment Dependencies Update r-base 3.6.2 -\textgreater 3.6.3 Update r-xfun 0.15 -\textgreater 0.20}
}
@misc{ro-crate-metadata-file,
title = {Root Data Entity - Research Object Crate ({RO}-Crate) Root Data Entity \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/root-data-entity.html\#ro-crate-metadata-file-descriptor},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{rocrate-root,
title = {Root Data Entity - Research Object Crate ({RO}-Crate) Root Data Entity \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/root-data-entity.html\#direct-properties-of-the-root-data-entity},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@techreport{doi:10.17487/rfc8493,
title = {The {BagIt} File Packaging Format (V1.0)},
author = {Kunze, J. and Littman, J. and Madden, E. and Scancella, J. and Adams, C.},
publisher = {{RFC} Editor},
url = {https://www.rfc-editor.org/info/rfc8493},
year = {2018},
month = {oct},
urldate = {2021-05-04},
doi = {10.17487/{RFC8493}},
sciwheel-projects = {ro-crate-paper},
abstract = {This document specifies {BagIt}, a hierarchical file packaging format for storage and transfer of arbitrary digital content. A "bag" has just enough structure to enclose descriptive "tags" and a "payload" but does not require knowledge of the payload's internal semantics. This {BagIt} format should be suitable for disk-based or network-based storage and transfer. {BagIt} is widely used in the practice of digital preservation.}
}
@techreport{ocfl_2020,
title = {Oxford Common File Layout Specification},
author = {{OCFL},},
editor = {Hankinson, Andrew and Jefferies, Neil and Metz, Rosalyn and Morley, Julian and Warner, Simeon and Woods, Andrew},
publisher = {OCFL},
url = {https://ocfl.io/1.0/spec/},
year = {2020},
month = {jul},
day = {7},
urldate = {2021-05-04},
edition = {1.0},
sciwheel-projects = {ro-crate-paper},
type = {Recommendation}
}

@misc{rocrate-contextualentities,
title = {Contextual Entities - Research Object Crate ({RO}-Crate) Contextual Entities \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/contextual-entities.html\#contextual-vs-data-entities},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}

@techreport{httprange14,
title = {Dereferencing {HTTP} {URIs}},
author = {{W3C Technical Architecture Group}},
editor = {Lewis, Rhys},
publisher = {W3C},
url = {https://www.w3.org/2001/tag/doc/{httpRange}-14/2007-08-31/{HttpRange}-14.html},
year = {2007},
month = {aug},
day = {31},
urldate = {2021-05-04},
edition = {2007-08-31},
sciwheel-projects = {ro-crate-paper},
type = {Draft Tag Finding}
}

@techreport{sporny_2014,
title = {{JSON}-{LD} 1.0},
author = {Sporny, Manu and Longley, Dave and Kellogg, Gregg and Lanthaler, Markus and Lindström, Niklas},
publisher = {W3C},
url = {https://www.w3.org/{TR}/2014/{REC}-json-ld-20140116/},
year = {2014},
month = {jan},
day = {16},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {{W3C} Recommendation}
}

@misc{schema.org,
title = {Schema.org - Schema.org},
url = {https://schema.org/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}

@report{doi:10.5281/zenodo.4541002,
title = {{RO}-Crate Metadata Specification 1.1.1},
author = {Sefton, Peter and Carragáin, Eoghan Ó and Soiland-Reyes, Stian and Corcho, Oscar and Garijo, Daniel and Palma, Raul and Coppens, Frederik and Goble, Carole and Fernández, José María and Chard, Kyle and Gomez-Perez, Jose Manuel and Crusoe, Michael R and Eguinoa, Ignacio and Juty, Nick and Holmes, Kristi and Clark, Jason A. and Capella-Gutierrez, Salvador and Gray, Alasdair J. G. and Owen, Stuart and Williams, Alan R. and Tartari, Giacomo and Bacall, Finn and Thelen, Thomas and Ménager, Hervé and Navas, Laura Rodríguez and Walk, Paul and Whitehead, Brandon and Wilkinson, Mark and Groth, Paul and Bremer, Erich and Castro, {LJ} Garcia and Sebby, Karl and Kanitz, Alexander and Trisovic, Ana and Kennedy, Gavin and Graves, Mark and Koehorst, Jasper and Leo, Simone and Portier, Marc},
url = {https://w3id.org/ro/crate/1.1},
year = {2021},
urldate = {2021-05-04},
journal = {Zenodo},
doi = {10.5281/zenodo.4541002},
sciwheel-projects = {ro-crate-paper},
abstract = {Web-version: https://w3id.org/ro/crate/1.1 This document specifies a method, known as {RO}-Crate (Research Object Crate), of aggregating and describing research data with associated metadata. {RO}-Crates can aggregate and describe any resource including files, {URI}-addressable resources, or use other addressing schemes to locate digital or physical data. {RO}-Crates can describe data in aggregate and at the individual resource level, with metadata to aid in discovery, re-use and long term management of data. Metadata includes the ability to describe the context of data and the entities involved in its production, use and reuse. For example: who created it, using which equipment, software and workflows, under what licenses can it be re-used, where was it collected, and/or where is it about. {RO}-Crate uses {JSON}-{LD} to to express this metadata using linked data, describing data resources as well as contextual entities such as people, organizations, software and equipment as a series of linked {JSON}-{LD} objects - using common published vocabularies, chiefly schema.org. The core of {RO}-Crate is a {JSON}-{LD} file, the {RO}-Crate Metadata File, named ro-crate-metadata.json. This file contains structured metadata about the dataset as a whole (the Root Data Entity) and, optionally, about some or all of its files. This provides a simple way to, for example, assert the authors (e.g. people, organizations) of the {RO}-Crate or one its files, or to capture more complex provenance for files, such as how they were created using software and equipment. While providing the formal specification for {RO}-Crate, this document also aims to be a practical guide for software authors to create tools for generating and consuming research data packages, with explanation by examples.}
}
@misc{ro-crate-issue-71,
title = {Use Case: As a researcher I want to be able to define ad hoc properties and use them in a crate without resorting to the verbose {PropertyValue} thing · Issue \#71 · {ResearchObject}/ro-crate · {GitHub}},
url = {https://github.com/{ResearchObject}/ro-crate/issues/71},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-jsonld,
title = {{RO}-Crate {JSON}-{LD} - Research Object Crate ({RO}-Crate) {RO}-Crate {JSON}-{LD} \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/appendix/jsonld.html},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro2018,
title = {Workshop on Research Objects ({RO2018})},
url = {https://www.researchobject.org/ro2018/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{rda11-data-packaging,
title = {Approaches to Research Data Packaging - {RDA} 11th Plenary {BoF} meeting \textbar {RDA}},
url = {https://rd-alliance.org/approaches-research-data-packaging-rda-11th-plenary-bof-meeting},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@article{doi:10.5281/zenodo.3250687,
title = {A lightweight approach to research object data packaging},
author = {Carragáin, Eoghan Ó and Goble, Carole and Sefton, Peter and Soiland-Reyes, Stian},
year = {2019},
urldate = {2021-05-04},
journal = {Zenodo},
doi = {10.5281/zenodo.3250687},
sciwheel-projects = {ro-crate-paper},
abstract = {A Research Object ({RO}) provides a machine-readable mechanism to communicate the diverse set of digital and real-world resources that contribute to an item of research. The aim of an {RO} is to evolve from traditional academic publication as a static {PDF}, to rather provide a complete and structured archive of the items (such as people, organisations, funding, equipment, software etc) that contributed to the research outcome, including their identifiers, provenance, relations and annotations. This is of particular importance as all domains of research and science are increasingly relying on computational analysis, yet we are facing a reproducibility crisis because key components are often not sufficiently tracked, archived or reported. Here we propose Research Object Crate (or {RO}-Crate for short), an emerging lightweight approach to packaging research data with their structured metadata, rephrasing the Research Object model as schema.org annotations to formalize a {JSON}-{LD} format that can be used independently of infrastructure, e.g. in {GitHub} or Zenodo archives. {RO}-Crate can be extended for domain-specific descriptions, aiming at a wide variety of applications and repositories to encourage {FAIR} sharing of reproducible datasets and analytical methods.}
}
@article{doi:10.5281/zenodo.1445817,
title = {Datacrate Submisssion To The Workshop On Research Objects},
author = {Sefton, Peter},
year = {2018},
urldate = {2021-05-04},
journal = {Zenodo},
doi = {10.5281/zenodo.1445817},
sciwheel-projects = {ro-crate-paper},
abstract = {This is a somewhat experimental approach to submitting an extended abstract to a conference. The submission describes the {DataCrate} standard and the source-files, {HTML} and {PDF} versions of the submission are included in a {DataCrate} package.}
}
@misc{researchobject/ro-crate,
title = {{GitHub} - {ResearchObject}/ro-crate: Research Object Crate},
url = {https://github.com/researchobject/ro-crate/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-community,
title = {Community - Research Object Crate ({RO}-Crate) Community \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/community},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{criminalcharacters,
title = {Home page - Criminal Characters},
url = {https://criminalcharacters.com/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{describo,
title = {github-pages},
url = {https://arkisto-platform.github.io/describo/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{describo-online,
title = {github-pages},
url = {https://arkisto-platform.github.io/describo-online/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-excel,
title = {ro-crate-excel - npm},
url = {https://www.npmjs.com/package/ro-crate-excel},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-html-js,
title = {ro-crate-html-js - npm},
url = {https://www.npmjs.com/package/ro-crate-html-js},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-js,
title = {{GitHub} - {UTS}-{eResearch}/ro-crate-js: Research Object Crate ({RO}-Crate) utilities},
url = {https://github.com/{UTS}-{eResearch}/ro-crate-js},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-ruby,
title = {{GitHub} - {ResearchObject}/ro-crate-ruby: A Ruby gem for creating, manipulating and reading {RO}-Crates.},
url = {https://github.com/{ResearchObject}/ro-crate-ruby},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-py,
title = {{GitHub} - {ResearchObject}/ro-crate-py: Python library for {RO}-Crate},
url = {https://github.com/researchobject/ro-crate-py},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{about-workflowhub,
title = {{WorkflowHub} project \textbar Project pages for developing and running the {WorkflowHub}, a registry of scientific workflows.},
url = {https://about.workflowhub.eu/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{modpdsc,
title = {{GitHub} - {CoEDL}/modpdsc},
url = {https://github.com/{CoEDL}/modpdsc/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{arkisto-data-portal,
title = {Tools: Data Portal \& Discovery},
url = {https://arkisto-platform.github.io/tools/portal/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ocfl-tools,
title = {{GitHub} - {CoEDL}/ocfl-tools: Tools to process and manipulate an {OCFL} tree},
url = {https://github.com/{CoEDL}/ocfl-tools},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-composer,
title = {Ro Composer},
url = {https://esciencelab.org.uk/projects/ro-composer/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{galaxy2cwl,
title = {{GitHub} - workflowhub-eu/galaxy2cwl: Standalone version tool to get cwl descriptions (initially an abstract cwl interface) of galaxy workflows and Galaxy workflows executions.},
url = {https://github.com/workflowhub-eu/galaxy2cwl},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{bioschemas-computationalworkflow,
title = {Bioschemas ComputationalWorkflow 1.0},
url = {https://bioschemas.org/profiles/{ComputationalWorkflow}/1.0-{RELEASE}/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{rocrate-workflows,
title = {Workflows and scripts - Research Object Crate ({RO}-Crate) Workflows and scripts \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/workflows.html},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{workflow-ro-crate,
title = {Workflow {RO}-Crate ({DRAFT}) \textbar {WorkflowHub} project},
url = {https://about.workflowhub.eu/Workflow-{RO}-Crate/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{elixir,
title = {{ELIXIR} \textbar A distributed infrastructure for life-science information},
url = {https://elixir-europe.org/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{eosc-life,
title = {Home - {EOSC} Life},
url = {https://www.eosc-life.eu/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{workflowhub,
title = {The {WorkflowHub}},
url = {https://workflowhub.eu/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{bco,
title = {{BioCompute} Objects},
url = {https://www.biocomputeobject.org/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{doi:10.1109/IEEESTD.2020.9094416,
title = {2791-2020 - {IEEE} Standard for Bioinformatics Analyses Generated by High-Throughput Sequencing ({HTS}) to Facilitate Communication \textbar {IEEE} Standard \textbar {IEEE} Xplore},
doi = {10.1109/{IEEESTD}.2020.9094416},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ieee-2791-schema,
title = {2791 object / ieee-2791-schema · {GitLab}},
url = {https://opensource.ieee.org/2791-object/ieee-2791-schema/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{bco-ro-crate,
title = {{BioCompute} Objects {RO}-Crate · Tutorial and specification for packaging {IEEE} 2791-2020 as {RO}-Crate Research ...},
url = {https://biocompute-objects.github.io/bco-ro-crate/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-implementation-notes,
title = {Implementation notes - Research Object Crate ({RO}-Crate) Implementation notes \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/appendix/implementation-notes.html\#adding-ro-crate-to-bagit},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{paradisec,
title = {{PARADISEC} – Safeguarding research in Australia's region},
url = {https://www.paradisec.org.au/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{case-study-paradisec,
title = {Case Study: Modern {PARADISEC}},
url = {https://arkisto-platform.github.io/case-studies/paradisec/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@article{doi:10.1016/j.patter.2020.100136,
title = {Dataset reuse: toward translating principles to practice.},
author = {Koesten, Laura and Vougiouklis, Pavlos and Simperl, Elena and Groth, Paul},
pages = {100136},
year = {2020},
month = {nov},
day = {13},
journal = {Patterns (New York, N.Y.)},
volume = {1},
number = {8},
issn = {26663899},
doi = {10.1016/j.patter.2020.100136},
pmid = {33294873},
pmcid = {PMC7691392},
sciwheel-projects = {ro-crate-paper},
abstract = {The web provides access to millions of datasets that can have additional impact when used beyond their original context. We have little empirical insight into what makes a dataset more reusable than others and which of the existing guidelines and frameworks, if any, make a difference. In this paper, we explore potential reuse features through a literature review and present a case study on datasets on {GitHub}, a popular open platform for sharing code and data. We describe a corpus of more than 1.4 million data files, from over 65,000 repositories. Using {GitHub}'s engagement metrics as proxies for dataset reuse, we relate them to reuse features from the literature and devise an initial model, using deep neural networks, to predict a dataset's reusability. This demonstrates the practical gap between principles and actionable insights that allow data publishers and tools designers to implement functionalities that provably facilitate reuse. \copyright 2020 The Authors.}
}
@inproceedings{doi:10.1190/1.1822162,
title = {Electronic documents give reproducible research a new meaning},
author = {Claerbout, Jon F. and Karrenbach, Martin},
pages = {601-604},
publisher = {Society of Exploration Geophysicists},
year = {1992},
month = {jan},
urldate = {2021-05-04},
doi = {10.1190/1.1822162},
sciwheel-projects = {ro-crate-paper},
booktitle = {{SEG} Technical Program Expanded Abstracts 1992}
}
@inproceedings{newman2009,
       booktitle = {Proceedings of the Workshop on Semantic Web Applications in Scientific Discourse (SWASD 2009)},
          editor = {Clark, Tim and Luciano, Joanne S. and Marshall, M. Scott and Prud’Hommeaux, Eric and Stephens, Susie},       
          series = {CEUR Workshop Proceedings},
       collection={CEUR Workshop Proceedings},          
           month = {Oct},
           title = {{myExperiment}: An ontology for e-Research},
          author = {David Newman and Sean Bechhofer and David De Roure},
            year = {2009},
            issn = {1613-0073},
           volume = {523},
           publisher={CEUR-WS},
            note = {2009-10-25},
             url = {http://ceur-ws.org/Vol-523/Newman.pdf},
        sciwheel-projects = {ro-crate-paper},
        abstract = {myExperiment describes itself as a "Social Virtual Research Environment" that provides the ability to share Research Objects (ROs) over a social infrastructure to facilitate actioning of research. The myExperiment Ontology is a logical representation of the data model used by this environment, allowing its data to be published in a standard RDF format, whilst providing a generic extensible framework that can be reused by similar projects. ROs are data structures designed to semantically enhance research publications by capturing and preserving the research method so that it can be reproduced in the future. This paper provides some motivation for an RO specification and briefly considers how existing domain-specifific ontologies might be integrated. It concludes by discussing the future direction of the myExperiment Ontology and how it will best support these ROs.}
}

@misc{myExperimentOntology2009,
title = {{myExperiment} Ontology Modules},
url = {http://web.archive.org/web/20091115080336/http\%3a\%2f\%2frdf.myexperiment.org/ontologies},
urldate = {2021-05-04},
year = {2009},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@article{doi:10.3390/publications8020021,
title = {{FAIR} digital objects for science: from data pieces to actionable knowledge units},
author = {De Smedt, Koenraad and Koureas, Dimitris and Wittenburg, Peter},
pages = {21},
year = {2020},
month = {apr},
day = {11},
urldate = {2021-05-04},
journal = {Publications},
volume = {8},
number = {2},
issn = {2304-6775},
doi = {10.3390/publications8020021},
sciwheel-projects = {ro-crate-paper},
abstract = {Data science is facing the following major challenges: (1) developing scalable cross-disciplinary capabilities, (2) dealing with the increasing data volumes and their inherent complexity, (3) building tools that help to build trust, (4) creating mechanisms to efficiently operate in the domain of scientific assertions, (5) turning data into actionable knowledge units and (6) promoting data interoperability. As a way to overcome these challenges, we further develop the proposals by early Internet pioneers for Digital Objects as encapsulations of data and metadata made accessible by persistent identifiers. In the past decade, this concept was revisited by various groups within the Research Data Alliance and put in the context of the {FAIR} Guiding Principles for findable, accessible, interoperable and reusable data. The basic components of a {FAIR} Digital Object ({FDO}) as a self-contained, typed, machine-actionable data package are explained. A survey of use cases has indicated the growing interest of research communities in {FDO} solutions. We conclude that the {FDO} concept has the potential to act as the interoperable federative core of a hyperinfrastructure initiative such as the European Open Science Cloud ({EOSC}).}
}

@misc{doip2.0,
title = {Digital Object Interface Protocol Specification 2.0},
author = {{DONA} Foundation,},
url = {https://www.dona.net/sites/default/files/2018-11/{DOIPv2Spec\_1}.pdf},
year = {2018},
month = {nov},
day = {14},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
abstract = {This document is a specification for the Digital Object Interface Protocol ({DOIP}), a core protocol of the Digital Object Architecture ({DO} Architecture; or {DOA}). The {DO} Architecture is a logical extension of the Internet architecture that addresses the need to support information management more generally than just conveying information in digital form from one location in the Internet to another. It is a non-proprietaryarchitecture and is publicly availablewithout charge. It is an outgrowth of earlier work on mobile programs,1and security for packet radio systems. The {DOIP} is intended to enable interoperability across heterogeneous information systems.},
journal = {{DONA} Foundation},
type = {WEBSITE}
}

@misc{fdof,
title = {{FAIR} Digital Object Framework Documentation},
url = {https://fairdigitalobjectframework.org/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}

@misc{ebi_ftp_umgs2019,
title = {{FTP} index of /pub/databases/metagenomics/umgs\_analyses/},
author = {{EMBL}-{EBI},},
url = {http://ftp.ebi.ac.uk/pub/databases/metagenomics/umgs\_analyses/},
year = {2019},
month = {sep},
day = {12},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
abstract = {{UMGS} genomes generated in this work were deposited in {ENA}, under the study accession {ERP108418}. The 92,143 {MAGs} with {QS} \textgreater50, as well as the quantification results from {BWA} and sourmash, all phylogenetic trees and the functional analysis results with {InterProScan}, {GP} and {GhostKOALA} are available at ftp://ftp.ebi.ac.uk/pub/databases/metagenomics/umgs\_analyses/. },
journal = {ftp.ebi.ac.uk},
notes = { Dataset of https://doi.org/10.1038/s41586-019-0965-1 }
type = {WEBSITE}
}


@misc{finn-lab-mgsgut,
title = {{GitHub} - Finn-Lab/{MGS}-gut: Analysing Metagenomic Species ({MGS})},
url = {https://github.com/Finn-Lab/{MGS}-gut},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
notes = { Scripts of https://doi.org/10.1038/s41586-019-0965-1 }
type = {WEBSITE}
}

@misc{sefton_blog_post_2021,
title = {{FAIR} Data Management; It's a lifestyle not a lifecycle - ptsefton.com},
author = {Sefton, Peter},
journal = {ptsefton.com},
url = {http://ptsefton.com/2021/04/07/rdmpic/},
year = {2021},
month = {apr},
day = {7},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {BLOG\_POST}
}


@misc{goble_presentation_2016,
title = {What is Reproducibility? The R* Brouhaha},
author = {Goble, Carole},
url = {http://repscience2016.research-infrastructures.eu/img/{CaroleGoble}-{ReproScience2016v2}.pdf},
year = {2016},
month = {sep},
day = {9},
urldate = {2021-05-04},
address = {Hannover, Germany},
sciwheel-projects = {ro-crate-paper},
type = {Keynote}
}


@misc{soilandreyes_tweet_2020,
title = {I am looking for which bioinformatics journals encourage authors to submit their code/pipeline/workflow *supporting* data analysis},
author = {Soiland-Reyes, Stian},
journal = {Twitter},
url = {https://twitter.com/soilandreyes/status/1250721245622079488},
year = {2020},
month = {apr},
day = {16},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
abstract = {I am looking for which bioinformatics journals encourage authors to submit their code/pipeline/workflow *supporting* data analysis, but so far I have only found vague references or special software article types. Usual suspects missing. See thread below; any more..?},
type = {thread}
}

@misc{anaconda-bioconda,
title = {bioconda :: Anaconda.org},
url = {https://anaconda.org/bioconda/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{biocontainers-registry,
title = {{BioContainers} Community},
url = {https://biocontainers.pro/\#/registry},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-terminology,
title = {Terminology - Research Object Crate ({RO}-Crate) Terminology \textbar Research Object Crate ({RO}-Crate)},
url = {https://www.researchobject.org/ro-crate/1.1/terminology},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@misc{ro-crate-issue-122,
title = {Use Case: {RO}-Crate as collection of contextual items · Issue \#122 · {ResearchObject}/ro-crate · {GitHub}},
url = {https://github.com/{ResearchObject}/ro-crate/issues/122},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}
@article{doi:10.1080/14490854.2020.1796500,
title = {Digital crowdsourcing and public understandings of the past: citizen historians meet Criminal Characters},
author = {Piper, Alana},
pages = {525-541},
url = {https://www.tandfonline.com/doi/full/10.1080/14490854.2020.1796500},
year = {2020},
month = {jul},
day = {2},
urldate = {2021-05-04},
journal = {History Australia},
volume = {17},
number = {3},
issn = {1449-0854},
doi = {10.1080/14490854.2020.1796500},
sciwheel-projects = {ro-crate-paper}
}
@incollection{doi:10.1515/9783110636352-017,
booktitle = {Making Histories},
author = {Piper, Alana},
title = {Chapter 16. crowdsourcing: citizen history and criminal characters},
editor = {Ashton, Paul and Evans, Tanya and Hamilton, Paula},
pages = {199-210},
publisher = {De Gruyter Oldenbourg},
year = {2020},
month = {sep},
day = {21},
urldate = {2021-05-04},
isbn = {9783110636352},
doi = {10.1515/9783110636352-017},
sciwheel-projects = {ro-crate-paper}
}
@misc{research-object-composer,
title = {{GitHub} - {ResearchObject}/research-object-composer: Research Object Composer, an {API} for incremental building and depositing research objects},
url = {https://github.com/researchobject/research-object-composer/},
urldate = {2021-05-04},
sciwheel-projects = {ro-crate-paper},
type = {WEBSITE}
}

@article{doi:10.1016/j.tibtech.2012.02.002,
title = {{ELIXIR}: a distributed infrastructure for European biological data.},
author = {Crosswell, Lindsey C and Thornton, Janet M},
pages = {241-242},
url = {http://dx.doi.org/10.1016/j.tibtech.2012.02.002},
year = {2012},
month = {may},
urldate = {2021-05-04},
journal = {Trends in Biotechnology},
volume = {30},
number = {5},
doi = {10.1016/j.tibtech.2012.02.002},
pmid = {22417641},
sciwheel-projects = {ro-crate-paper}
}
@incollection{doi:10.4018/978-1-60960-593-3.ch008,
booktitle = {Semantic services, interoperability and web applications: emerging concepts},
title = {Linked data: the story so far},
author = {Bizer, Christian and Heath, Tom and Berners-Lee, Tim},
editor = {Sheth, Amit},
pages = {205-227},
publisher = {{IGI} Global},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-60960-593-3.ch008},
year = {2011},
urldate = {2021-05-04},
isbn = {9781609605933},
doi = {10.4018/978-1-60960-593-3.ch008},
sciwheel-projects = {ro-crate-paper},
abstract = {The term {\textquotedblleftLinked} Data\textquotedblright refers to a set of best practices for publishing and connecting structured data on the Web. These best practices have been adopted by an increasing number of data providers over the last three years, leading to the creation of a global data space containing billions of assertions\textemdash the Web of Data. In this article, the authors present the concept and technical principles of Linked Data, and situate these within the broader context of related technological developments. They describe progress to date in publishing Linked Data on the Web, review applications that have been developed to exploit the Web of Data, and map out a research agenda for the Linked Data community as it moves forward.}
}
