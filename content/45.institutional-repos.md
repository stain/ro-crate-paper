## Institutional data repositories â€“ Harvard Data Commons

WORK IN PROGRESS. Data Commons is an effort to integrate active data-centric research with data management and archival best practices. Its goal is to accelerate discoveries by providing a cloud-based platform where researchers can use, share and store data, software, workflows, and other digital objects used in science. It brings together software tools and services for research, cloud computation and storage for scalability, and data repositories for sharing and archival. Multiple initiatives were undertaken to create Data Common on national, research, and institutional levels. For example, Australian Research Data Commons (ARDC) (https://ardc.edu.au) is a national initiative that enables local researchers and industries to access computing infrastructure, training, and curated datasets for data-intensive research. Genomic Data Commons (GDC) provides the cancer research community with access to genomic data. GDC contains an extensive collection amounting to over 3 PB of genomic and clinical data, and it has become one of the most significant and widely-used resources in cancer genomics. Harvard Data Commons is an example of an active undertaking at the institutional level. 

Harvard Data Commons aims to address the challenges of the institutional research community. In particular, its uncoordinated growth resulted in creating disconnected research services across units and schools, which led to difficulties in data sharing across the groups and multiple purchases of the same datasets. Other problems included a lack of data documentation and the risk of non-compliance with data policies. Harvard Data Commons would support institutional researchers by enabling them to browse through the University's breadth of resources and services such as access and reuse of (unpublished and published) data, data purchase, licensing, and management. In particular, a metadata registry would track all active datasets and their descriptions and thus act as an entry point for collaboration. In addition, researchers would be able to receive specialized support for publishing large and sensitive datasets. Harvard Data Commons is a collaboration between the institutional schools, the library, the research computing centre, and the Harvard Dataverse data repository (https://dataverse.harvard.edu/). Dataverse (https://dataverse.org/) is a free and open-source software platform to archive, share and cite research data. It is developed and maintained by Harvard's Institute for Quantitative Social Science (IQSS) and the Dataverse community. There are currently 70 Dataverse installations deployed across six continents. The Harvard Dataverse repository is the largest installation containing over 100K datasets with about 1M data files. It is open to all researchers worldwide, across disciplines, and it supports all data types. 

Harvard Data Commons would provide an interoperability framework between research tools and cloud computing for data processing and Dataverse for data management and archival (Figure~\ref{fig:hdc}). In practice, researchers often conduct data cleaning, processing, and exploration without documenting every single step of their research. Even files like group notes and presentations often do not make the finished product that follows a publication. As a result, external researchers may be unable to reconstruct the whole analysis process and reproduce the analysis. In contrast, some researchers use workflows and virtual containers to automate and encapsulate their data, code, and runtime environments for reproducibility. These tools are relatively novel and not yet adopted in many research infrastructures. Considering these diverse research paths, RO-Crate would provide a holistic approach in recording studies that incorporate data and code coming from a variety of institutional infrastructures in addition to workflows, containers, and contextual documents like reports and presentations. RO-Crate metadata schema provides the necessary flexibility to make all outputs from a study FAIR. Dataverse software already has extensive support for metadata, including the Data Documentation Initiative (DDI), Dublin Core, DataCite, and Schema.org. Incorporating RO-Crate, which has the flexibility to describe a wide range of research resources, would facilitate seamless study transitions throughout the research life cycle.




\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{content/images/data-commons-ro-crate-figure.pdf}
    \caption{Schematic view of Harvard Data Commons. It can be roughly divided into "Active Data-Intensive Research" infrastructure for ongoing studies across the University and "Published Data and Research" infrastructure for completed, published, or shared studies. }
    \label{fig:hdc}
\end{figure}